{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46242a7b-8aee-4217-802a-f9a9f82c5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from lightly.transforms import SimCLRTransform, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55a343-44c7-4a8d-af18-269a64917440",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 128\n",
    "seed = 1\n",
    "epochs = 50\n",
    "input_size = 256\n",
    "\n",
    "# dimension of the embeddings\n",
    "num_ftrs = 512\n",
    "# dimension of the output of the prediction and projection heads\n",
    "out_dim = proj_hidden_dim = 512\n",
    "# the prediction head uses a bottleneck architecture\n",
    "pred_hidden_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3a3b7-bb8b-4aa5-8541-0b23e065e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed torch and numpy\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# set the path to the dataset\n",
    "path_to_data = '/home/plaiground/Documents/dataset/bodimgsplit/training/'\n",
    "#path_to_data = \"/home/plaiground/Documents/dataset/debinolabel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dec4c1-f3ae-4108-aa0c-6c732cb2716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the augmentations for self-supervised learning\n",
    "transform = SimCLRTransform(\n",
    "    input_size=input_size,\n",
    "    # require invariance to flips and rotations\n",
    "    hf_prob=0.5,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5,\n",
    "    # satellite images are all taken from the same height\n",
    "    # so we use only slight random cropping\n",
    "    min_scale=0.5,\n",
    "    # use a weak color jitter for invariance w.r.t small color changes\n",
    "    cj_prob=0.2,\n",
    "    cj_bright=0.1,\n",
    "    cj_contrast=0.1,\n",
    "    cj_hue=0.1,\n",
    "    cj_sat=0.1,\n",
    ")\n",
    "\n",
    "# create a lightly dataset for training with augmentations\n",
    "dataset_train_simsiam = LightlyDataset(input_dir=path_to_data, transform=transform)\n",
    "\n",
    "# create a dataloader for training\n",
    "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
    "    dataset_train_simsiam,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "# create a torchvision transformation for embedding the dataset after training\n",
    "# here, we resize the images to match the input size during training and apply\n",
    "# a normalization of the color channel based on statistics from imagenet\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a lightly dataset for embedding\n",
    "dataset_test = LightlyDataset(input_dir=path_to_data, transform=test_transforms)\n",
    "\n",
    "# create a dataloader for embedding\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71f982-9fef-40ee-9d24-83777d6b9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SimSiamProjectionHead(num_ftrs, proj_hidden_dim, out_dim)\n",
    "        self.prediction_head = SimSiamPredictionHead(out_dim, pred_hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get representations\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        # get projections\n",
    "        z = self.projection_head(f)\n",
    "        # get predictions\n",
    "        p = self.prediction_head(z)\n",
    "        # stop gradient\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "\n",
    "# we use a pretrained resnet for this tutorial to speed\n",
    "# up training time but you can also train one from scratch\n",
    "resnet = torchvision.models.resnet18()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95fba4-83c1-49ca-a641-c11b4ae229dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimSiam uses a symmetric negative cosine similarity loss\n",
    "criterion = NegativeCosineSimilarity()\n",
    "\n",
    "# scale the learning rate\n",
    "lr = 0.05 * batch_size / 256\n",
    "# use SGD with momentum and weight decay\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b67a3-6e5c-47db-88a4-339abe89a25e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/ImageFile.py\", line 249, in load\n    s = read(self.decodermaxblock)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/PngImagePlugin.py\", line 957, in load_read\n    cid, pos, length = self.png.read()\n                       ^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/PngImagePlugin.py\", line 179, in read\n    length = i32(s)\n             ^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n           ^^^^^^^^^^^^^^^^^^^^^^^\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/lightly/data/dataset.py\", line 238, in __getitem__\n    sample, target = self.dataset.__getitem__(index)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 248, in pil_loader\n    return img.convert(\"RGB\")\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py\", line 937, in convert\n    self.load()\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/ImageFile.py\", line 256, in load\n    raise OSError(msg) from e\nOSError: image file is truncated\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m avg_output_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (x0, x1), _, _ \u001b[38;5;129;01min\u001b[39;00m dataloader_train_simsiam:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# move images to the gpu\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         x0 \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         x1 \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/ImageFile.py\", line 249, in load\n    s = read(self.decodermaxblock)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/PngImagePlugin.py\", line 957, in load_read\n    cid, pos, length = self.png.read()\n                       ^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/PngImagePlugin.py\", line 179, in read\n    length = i32(s)\n             ^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n           ^^^^^^^^^^^^^^^^^^^^^^^\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/lightly/data/dataset.py\", line 238, in __getitem__\n    sample, target = self.dataset.__getitem__(index)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/torchvision/datasets/folder.py\", line 248, in pil_loader\n    return img.convert(\"RGB\")\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py\", line 937, in convert\n    self.load()\n  File \"/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/ImageFile.py\", line 256, in load\n    raise OSError(msg) from e\nOSError: image file is truncated\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "avg_loss = 0.0\n",
    "avg_output_std = 0.0\n",
    "for e in range(epochs):\n",
    "    for (x0, x1), _, _ in dataloader_train_simsiam:\n",
    "        # move images to the gpu\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "\n",
    "        # run the model on both transforms of the images\n",
    "        # we get projections (z0 and z1) and\n",
    "        # predictions (p0 and p1) as output\n",
    "        z0, p0 = model(x0)\n",
    "        z1, p1 = model(x1)\n",
    "\n",
    "        # apply the symmetric negative cosine similarity\n",
    "        # and run backpropagation\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate the per-dimension standard deviation of the outputs\n",
    "        # we can use this later to check whether the embeddings are collapsing\n",
    "        output = p0.detach()\n",
    "        output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "        output_std = torch.std(output, 0)\n",
    "        output_std = output_std.mean()\n",
    "\n",
    "        # use moving averages to track the loss and standard deviation\n",
    "        w = 0.9\n",
    "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "\n",
    "    # the level of collapse is large if the standard deviation of the l2\n",
    "    # normalized output is much smaller than 1 / sqrt(dim)\n",
    "    collapse_level = max(0.0, 1 - math.sqrt(out_dim) * avg_output_std)\n",
    "    # print intermediate results\n",
    "    print(\n",
    "        f\"[Epoch {e:3d}] \"\n",
    "        f\"Loss = {avg_loss:.2f} | \"\n",
    "        f\"Collapse Level: {collapse_level:.2f} / 1.00\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac4b55-28b3-404b-afea-9a75158e71b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.fit() got an unexpected keyword argument 'train_dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m\n\u001b[1;32m    204\u001b[0m model \u001b[38;5;241m=\u001b[39m SimSiamModel(dataloader_train_kNN)\n\u001b[1;32m    205\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[TQDMProgressBar(refresh_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)])\n\u001b[0;32m--> 207\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_train_ssl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_test\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHighest test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmax_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.fit() got an unexpected keyword argument 'train_dataloader'"
     ]
    }
   ],
   "source": [
    "#skip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import lightly\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "\n",
    "num_workers = 8\n",
    "max_epochs = 800\n",
    "knn_k = 200\n",
    "knn_t = 0.1\n",
    "classes = 25\n",
    "batch_size = 512\n",
    "seed=1\n",
    "\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "# use a GPU if available\n",
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Use SimCLR augmentations, additionally, disable blur\n",
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=32,\n",
    "    gaussian_blur=0.,\n",
    ")\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "#dataset_train_ssl = dataset_train_simsiam\n",
    "dataset_train_ssl = dataset_train_simsiam\n",
    "#    torchvision.datasets.CIFAR10(\n",
    "#       root='data',\n",
    "#      train=True))\n",
    "#        download=True))\n",
    "dataset_train_kNN = LightlyDataset(input_dir=path_to_data, \n",
    "#    root='data',\n",
    "#     train=True,\n",
    "     transform=test_transforms)\n",
    "#    download=True))\n",
    "\n",
    "dataset_test = dataset_test\n",
    "#    root='data',\n",
    "#   train=False,\n",
    "#    transform=test_transforms))\n",
    "    #download=True))\n",
    "\n",
    "dataloader_train_ssl = torch.utils.data.DataLoader(\n",
    "    dataset_train_ssl,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "dataloader_train_kNN = torch.utils.data.DataLoader(\n",
    "    dataset_train_kNN,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# code for kNN prediction from here:\n",
    "# https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes: int, knn_k: int, knn_t: float):\n",
    "    \"\"\"Helper method to run kNN predictions on features based on a feature bank\n",
    "\n",
    "    Args:\n",
    "        feature: Tensor of shape [N, D] consisting of N D-dimensional features\n",
    "        feature_bank: Tensor of a database of features used for kNN\n",
    "        feature_labels: Labels for the features in our feature_bank\n",
    "        classes: Number of classes (e.g. 10 for CIFAR-10)\n",
    "        knn_k: Number of k neighbors used for kNN\n",
    "        knn_t: \n",
    "\n",
    "    \"\"\"\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
    "    # we do a reweighting of the similarities \n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels\n",
    "\n",
    "\n",
    "class BenchmarkModule(pl.LightningModule):\n",
    "    \"\"\"A PyTorch Lightning Module for automated kNN callback\n",
    "    \n",
    "    At the end of every training epoch we create a feature bank by inferencing\n",
    "    the backbone on the dataloader passed to the module. \n",
    "    At every validation step we predict features on the validation data.\n",
    "    After all predictions on validation data (validation_epoch_end) we evaluate\n",
    "    the predictions on a kNN classifier on the validation data using the \n",
    "    feature_bank features from the train data.\n",
    "    We can access the highest accuracy during a kNN prediction using the \n",
    "    max_accuracy attribute.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader_kNN):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Module()\n",
    "        self.max_accuracy = 0.0\n",
    "        self.dataloader_kNN = dataloader_kNN\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # update feature bank at the end of each training epoch\n",
    "        self.backbone.eval()\n",
    "        self.feature_bank = []\n",
    "        self.targets_bank = []\n",
    "        with torch.no_grad():\n",
    "            for data in self.dataloader_kNN:\n",
    "                img, target, _ = data\n",
    "                if gpus > 0:\n",
    "                    img = img.cuda()\n",
    "                    target = target.cuda()\n",
    "                feature = self.backbone(img).squeeze()\n",
    "                feature = F.normalize(feature, dim=1)\n",
    "                self.feature_bank.append(feature)\n",
    "                self.targets_bank.append(target)\n",
    "        self.feature_bank = torch.cat(self.feature_bank, dim=0).t().contiguous()\n",
    "        self.targets_bank = torch.cat(self.targets_bank, dim=0).t().contiguous()\n",
    "        self.backbone.train()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # we can only do kNN predictions once we have a feature bank\n",
    "        if hasattr(self, 'feature_bank') and hasattr(self, 'targets_bank'):\n",
    "            images, targets, _ = batch\n",
    "            feature = self.backbone(images).squeeze()\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            pred_labels = knn_predict(feature, self.feature_bank, self.targets_bank, classes, knn_k, knn_t)\n",
    "            num = images.size(0)\n",
    "            top1 = (pred_labels[:, 0] == targets).float().sum().item()\n",
    "            return (num, top1)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if outputs:\n",
    "            total_num = 0\n",
    "            total_top1 = 0.\n",
    "            for (num, top1) in outputs:\n",
    "                total_num += num\n",
    "                total_top1 += top1\n",
    "            acc = float(total_top1 / total_num)\n",
    "            if acc > self.max_accuracy:\n",
    "                self.max_accuracy = acc\n",
    "            self.log('kNN_accuracy', acc * 100.0, prog_bar=True)\n",
    "\n",
    "\n",
    "class SimSiamModel(BenchmarkModule):\n",
    "    def __init__(self, dataloader_kNN):\n",
    "        super().__init__(dataloader_kNN)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = lightly.models.ResNetGenerator('resnet-18')\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        # create a simsiam model based on ResNet\n",
    "        self.resnet_simsiam = \\\n",
    "            lightly.models.SimSiam(self.backbone, num_ftrs=512, out_dim=2)\n",
    "        self.criterion = lightly.loss.SymNegCosineSimilarityLoss()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        self.resnet_simsiam(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        x0, x1 = self.resnet_simsiam(x0, x1)\n",
    "        loss = self.criterion(x0, x1)\n",
    "        self.log('train_loss_ssl', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.resnet_simsiam.parameters(), lr=6e-2,\n",
    "                                momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "\n",
    "model = SimSiamModel(dataloader_train_kNN)\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, accelerator=\"gpu\",\n",
    "                    callbacks=[TQDMProgressBar(refresh_rate=100)])\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloader=dataloader_train_ssl,\n",
    "    val_dataloaders=dataloader_test\n",
    ")\n",
    "\n",
    "print(f'Highest test accuracy: {model.max_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c05d1-6713-478b-b04f-d81475f6c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing unit color from moco classifier: ini datasetnya saya split dulu 80,20 (training test)\n",
    "import copy\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.utils import deactivate_requires_grad                        \n",
    "from lightly.models.utils import update_momentum\n",
    "from lightly.models.utils import batch_shuffle\n",
    "from lightly.models.utils import batch_unshuffle\n",
    "from lightly.models import ResNetGenerator\n",
    "from lightly.models.modules.heads import MoCoProjectionHead\n",
    "from lightly.transforms import MoCoV2Transform, utils\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "#path_to_train = '/home/ismail/datasets/debisplit/training'\n",
    "#path_to_test = '/home/ismail/datasets/debisplit/test'\n",
    "num_workers = 8\n",
    "batch_size=512\n",
    "memory_bank_size=4096\n",
    "seed = 1\n",
    "max_epochs=300\n",
    "path_to_train = '/home/plaiground/Documents/dataset/debi872split/training/'\n",
    "path_to_test = '/home/plaiground/Documents/dataset/debi872split/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d9063-4a57-4678-ad66-3b6739be3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnnimage\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#use data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8b5dc-5db2-46b8-ae79-bc947f48dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class SpectrogramClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SpectrogramClassifier, self).__init__()\n",
    "        #self.model = models.resnet18(pretrained=True)\n",
    "        #self.model = models.resnet18(pretrained=False)\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.load_state_dict(torch.load('/home/plaiground/Documents/resnet-18/resnet18-f37072fd.pth'))\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        #x = self.model(x)  # Pass through pre-trained model (ResNet-18)\n",
    "        # Print feature shape before final layer\n",
    "        #print(f\"Spectrogram feature shape before final layer: {x.shape}\")\n",
    "        #x = self.fc(x)  # Final classification layer\n",
    "        #return x\n",
    "\n",
    "# Custom dataset class\n",
    "class SpectrogramDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.img_list = self.generate_img_list()\n",
    "\n",
    "    def generate_img_list(self):\n",
    "        img_list = []\n",
    "        for cls in self.classes:\n",
    "            cls_folder = os.path.join(self.root, cls)\n",
    "            for img_name in os.listdir(cls_folder):\n",
    "                img_list.append((os.path.join(cls_folder, img_name), cls))\n",
    "        return img_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, cls = self.img_list[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, self.class_to_idx[cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94329418-ebe6-4fe7-8e4b-028e40dd438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "root_folder = '/home/plaiground/Documents/dataset/maldeb/'\n",
    "dataset = SpectrogramDataset(root_folder, transform=transform)\n",
    "train_dataset=SpectrogramDataset(root_folder, transform=train_transform)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "# Set up datasets and dataloaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "num_classes = len(dataset.classes)\n",
    "model = SpectrogramClassifier(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466e9fc-cf27-430c-98be-5d477c827e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Accuracy: 0.95\n",
      "Epoch [2/100], Accuracy: 0.96\n",
      "Epoch [3/100], Accuracy: 0.97\n",
      "Epoch [4/100], Accuracy: 0.97\n",
      "Epoch [5/100], Accuracy: 0.97\n",
      "Epoch [6/100], Accuracy: 0.97\n",
      "Epoch [7/100], Accuracy: 0.97\n",
      "Epoch [8/100], Accuracy: 0.97\n",
      "Epoch [9/100], Accuracy: 0.97\n",
      "Epoch [10/100], Accuracy: 0.96\n",
      "Epoch [11/100], Accuracy: 0.98\n",
      "Epoch [12/100], Accuracy: 0.98\n",
      "Epoch [13/100], Accuracy: 0.98\n",
      "Epoch [14/100], Accuracy: 0.98\n",
      "Epoch [15/100], Accuracy: 0.98\n",
      "Epoch [16/100], Accuracy: 0.98\n",
      "Epoch [17/100], Accuracy: 0.98\n",
      "Epoch [18/100], Accuracy: 0.97\n",
      "Epoch [19/100], Accuracy: 0.97\n",
      "Epoch [20/100], Accuracy: 0.98\n",
      "Epoch [21/100], Accuracy: 0.98\n",
      "Epoch [22/100], Accuracy: 0.98\n",
      "Epoch [23/100], Accuracy: 0.98\n",
      "Epoch [24/100], Accuracy: 0.98\n",
      "Epoch [25/100], Accuracy: 0.97\n",
      "Epoch [26/100], Accuracy: 0.98\n",
      "Epoch [27/100], Accuracy: 0.98\n",
      "Epoch [28/100], Accuracy: 0.98\n",
      "Epoch [29/100], Accuracy: 0.98\n",
      "Epoch [30/100], Accuracy: 0.98\n",
      "Epoch [31/100], Accuracy: 0.98\n",
      "Epoch [32/100], Accuracy: 0.98\n",
      "Epoch [33/100], Accuracy: 0.98\n",
      "Epoch [34/100], Accuracy: 0.98\n",
      "Epoch [35/100], Accuracy: 0.98\n",
      "Epoch [36/100], Accuracy: 0.98\n",
      "Epoch [37/100], Accuracy: 0.98\n",
      "Epoch [38/100], Accuracy: 0.97\n",
      "Epoch [39/100], Accuracy: 0.98\n",
      "Epoch [40/100], Accuracy: 0.98\n",
      "Epoch [41/100], Accuracy: 0.98\n",
      "Epoch [42/100], Accuracy: 0.98\n",
      "Epoch [43/100], Accuracy: 0.98\n",
      "Epoch [44/100], Accuracy: 0.98\n",
      "Epoch [45/100], Accuracy: 0.98\n",
      "Epoch [46/100], Accuracy: 0.98\n",
      "Epoch [47/100], Accuracy: 0.98\n",
      "Epoch [48/100], Accuracy: 0.98\n",
      "Epoch [49/100], Accuracy: 0.98\n",
      "Epoch [50/100], Accuracy: 0.98\n",
      "Epoch [51/100], Accuracy: 0.98\n",
      "Epoch [52/100], Accuracy: 0.98\n",
      "Epoch [53/100], Accuracy: 0.98\n",
      "Epoch [54/100], Accuracy: 0.98\n",
      "Epoch [55/100], Accuracy: 0.98\n",
      "Epoch [56/100], Accuracy: 0.98\n",
      "Epoch [57/100], Accuracy: 0.98\n",
      "Epoch [58/100], Accuracy: 0.98\n",
      "Epoch [59/100], Accuracy: 0.98\n",
      "Epoch [60/100], Accuracy: 0.98\n",
      "Epoch [61/100], Accuracy: 0.98\n",
      "Epoch [62/100], Accuracy: 0.98\n",
      "Epoch [63/100], Accuracy: 0.98\n",
      "Epoch [64/100], Accuracy: 0.98\n",
      "Epoch [65/100], Accuracy: 0.98\n",
      "Epoch [66/100], Accuracy: 0.98\n",
      "Epoch [67/100], Accuracy: 0.98\n",
      "Epoch [68/100], Accuracy: 0.98\n",
      "Epoch [69/100], Accuracy: 0.98\n",
      "Epoch [70/100], Accuracy: 0.98\n",
      "Epoch [71/100], Accuracy: 0.98\n",
      "Epoch [72/100], Accuracy: 0.98\n",
      "Epoch [73/100], Accuracy: 0.98\n",
      "Epoch [74/100], Accuracy: 0.98\n",
      "Epoch [75/100], Accuracy: 0.98\n",
      "Epoch [76/100], Accuracy: 0.98\n",
      "Epoch [77/100], Accuracy: 0.98\n",
      "Epoch [78/100], Accuracy: 0.98\n",
      "Epoch [79/100], Accuracy: 0.98\n",
      "Epoch [80/100], Accuracy: 0.98\n",
      "Epoch [81/100], Accuracy: 0.98\n",
      "Epoch [82/100], Accuracy: 0.98\n",
      "Epoch [83/100], Accuracy: 0.98\n",
      "Epoch [84/100], Accuracy: 0.97\n",
      "Epoch [85/100], Accuracy: 0.98\n",
      "Epoch [86/100], Accuracy: 0.98\n",
      "Epoch [87/100], Accuracy: 0.98\n",
      "Epoch [88/100], Accuracy: 0.98\n",
      "Epoch [89/100], Accuracy: 0.98\n",
      "Epoch [90/100], Accuracy: 0.98\n",
      "Epoch [91/100], Accuracy: 0.98\n",
      "Epoch [92/100], Accuracy: 0.98\n",
      "Epoch [93/100], Accuracy: 0.98\n",
      "Epoch [94/100], Accuracy: 0.98\n",
      "Epoch [95/100], Accuracy: 0.98\n",
      "Epoch [96/100], Accuracy: 0.98\n",
      "Epoch [97/100], Accuracy: 0.98\n",
      "Epoch [98/100], Accuracy: 0.97\n",
      "Epoch [99/100], Accuracy: 0.98\n",
      "Epoch [100/100], Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf6649-e2a6-4d26-b339-0afb9d16d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'imgcnnmaldeb.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c019f5-1b45-4e56-939b-cb7b599c7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectro\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "root_folder = '/home/plaiground/Documents/dataset/maldebspectro/'\n",
    "dataset = SpectrogramDataset(root_folder, transform=transform)\n",
    "train_dataset=SpectrogramDataset(root_folder, transform=train_transform)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "# Set up datasets and dataloaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "num_classes = len(dataset.classes)\n",
    "model = SpectrogramClassifier(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957563c5-fb81-46dc-a2d3-786a4288bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85aeec6-2572-469f-b57c-fd7493ecf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'spectroCNNmaldeb.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade9727-d44f-47ed-8c91-3812bfda204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "#gemini late-fusion-average\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        # Assuming your SimCLR model has a final projection head\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        #torch.load(pretrained_model_path)\n",
    "        #self.classifier = nn.Linear(in_features=(1, 224, 224), out_features=2)  # Replace ... with actual input size\n",
    "        #resnet = torch.hub.load('pytorch/vision:v0.13.1', 'resnet18', pretrained=True)  # Load pre-trained ResNet\n",
    "        #resnet = torchvision.models.resnet18(pretrained=False)\n",
    "        #resnet = models.resnet18(pretrained=False)\n",
    "        #resnet = models.resnet18(weights=None)\n",
    "        #self.backbone = nn.Sequential(*list(resnet.children())[:-1])  # Extract backbone\n",
    "        #hidden_dim = resnet.fc.in_features\n",
    "        #self.classification_head = nn.Linear(hidden_dim, 2)\n",
    "        self.model.load_state_dict(torch.load('/home/plaiground/Documents/resnet-18/resnet18-f37072fd.pth'))\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.model(x)  # Use the entire loaded model for feature extraction\n",
    "        #x = self.classifier(x)\n",
    "        #return x\n",
    "        #h = self.backbone(x).flatten(start_dim=1)\n",
    "        #eturn self.classification_head(h)\n",
    "        return self.model(x)\n",
    "\n",
    "#class SpectrogramCNN(nn.Module):\n",
    "class SpectrogramClassifier(nn.Module):\n",
    "    #def __init__(self, model_path):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SpectrogramClassifier, self).__init__()\n",
    "        #self.model = models.resnet18(pretrained=False)\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.load_state_dict(torch.load('/home/plaiground/Documents/resnet-18/resnet18-f37072fd.pth'))\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "        #self.model = torch.load(model_path)  # Load the entire pre-trained spectrogram CNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define ImageClassifier wrapper\n",
    "class ImageClassifierWrapper(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_classes=2):\n",
    "        super(ImageClassifierWrapper, self).__init__()\n",
    "        self.model = ImageClassifier(num_classes)\n",
    "        self.load_pretrained_weights(pretrained_model_path)\n",
    "\n",
    "    def load_pretrained_weights(self, pretrained_model_path):\n",
    "        state_dict = torch.load(pretrained_model_path)\n",
    "        self.model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define SpectrogramClassifierWrapper\n",
    "class SpectrogramClassifierWrapper(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_classes=2):\n",
    "        super(SpectrogramClassifierWrapper, self).__init__()\n",
    "        self.model = SpectrogramClassifier(num_classes)\n",
    "        self.load_pretrained_weights(pretrained_model_path)\n",
    "\n",
    "    def load_pretrained_weights(self, pretrained_model_path):\n",
    "        state_dict = torch.load(pretrained_model_path)\n",
    "        self.model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MultimodalLateFusion(nn.Module):\n",
    "    def __init__(self, image_model_path, spectrogram_model_path):\n",
    "        super(MultimodalLateFusion, self).__init__()\n",
    "        self.image_model = ImageModel(image_model_path)\n",
    "        self.spectrogram_model = SpectrogramClassifier(spectrogram_model_path)\n",
    "        #image_features = self.image_model(image_sample)\n",
    "        #spectrogram_features = self.spectrogram_model(spectrogram_sample)\n",
    "        #print(f\"Image feature shape: {image_features.shape}\")\n",
    "        #print(f\"Spectrogram feature shape: {spectrogram_features.shape}\")\n",
    "        model = SpectrogramClassifier(num_classes=2)  # Replace 2 with your actual number of classes\n",
    "        spectrogram_dim = model.model.fc.in_features  # Assuming fc is the final layer\n",
    "        combined_feature_size = 128 + spectrogram_dim\n",
    "        self.fusion_layer = nn.Linear(combined_feature_size, 2)  # Replace ... with combined feature size\n",
    "\n",
    "    def forward(self, image, spectrogram):\n",
    "        image_features = self.image_model(image)\n",
    "        spectrogram_features = self.spectrogram_model(spectrogram)\n",
    "        # Concatenate features along channel dimension (dim=1)\n",
    "        combined_features = torch.cat((image_features, spectrogram_features), dim=1)\n",
    "        output = self.fusion_layer(combined_features)\n",
    "        return output\n",
    "\n",
    "# Define transforms for the datasets\n",
    "data_transforms = {\n",
    "    'images': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'spectrograms': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets\n",
    "image_dataset = ImageFolder(root='/home/plaiground/Documents/dataset/maldeb/', transform=data_transforms['images'])\n",
    "spectrogram_dataset = ImageFolder(root='/home/plaiground/Documents/dataset/maldebspectro/', transform=data_transforms['spectrograms'])\n",
    "\n",
    "# Create a custom dataset to pair images and spectrograms\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, image_dataset, spectrogram_dataset):\n",
    "        self.image_dataset = image_dataset\n",
    "        self.spectrogram_dataset = spectrogram_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_dataset[idx]\n",
    "        spectrogram, _ = self.spectrogram_dataset[idx]\n",
    "        return image, spectrogram, label\n",
    "\n",
    "# Create the paired dataset and dataloader\n",
    "paired_dataset = PairedDataset(image_dataset, spectrogram_dataset)\n",
    "test_loader = DataLoader(paired_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example usage\n",
    "image_model_path = \"/home/plaiground/Documents/multimodal/imgcnnmaldeb.pth\"\n",
    "spectrogram_model_path = \"/home/plaiground/Documents/multimodal/spectroCNNmaldeb.pth\"\n",
    "\n",
    "#image_model = SimCLRModel(image_model_path)\n",
    "#spectrogram_model = SpectrogramCNN(spectrogram_model_path)\n",
    "\n",
    "image_model = ImageClassifierWrapper(image_model_path)\n",
    "spectrogram_model = SpectrogramClassifierWrapper(spectrogram_model_path)\n",
    "\n",
    "# Set models to evaluation mode\n",
    "image_model.eval()\n",
    "spectrogram_model.eval()\n",
    "# Define your evaluation metric function (replace with your chosen metric)\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        #for images, spectrograms, labels in data_loader:\n",
    "            #images = images.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            #spectrograms = spectrograms.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        for data, labels in data_loader:\n",
    "            data = data.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            # Pass data through the late fusion model\n",
    "            #outputs = fusion_model(images, spectrograms)\n",
    "            #outputs = fusion_model(data)  # Assuming both data sources are combined within the model\n",
    "            outputs = model(data)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Function to get predictions from both models\n",
    "def get_predictions(image_tensor, spectrogram_tensor):\n",
    "    with torch.no_grad():\n",
    "        image_output = image_model(image_tensor)\n",
    "        spectrogram_output = spectrogram_model(spectrogram_tensor)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    image_probs = F.softmax(image_output, dim=1)\n",
    "    spectrogram_probs = F.softmax(spectrogram_output, dim=1)\n",
    "    \n",
    "    return image_probs, spectrogram_probs\n",
    "\n",
    "# Function to perform late fusion and make final decision\n",
    "def late_fusion(image_tensor, spectrogram_tensor):\n",
    "    image_probs, spectrogram_probs = get_predictions(image_tensor, spectrogram_tensor)\n",
    "    \n",
    "    # Combine the probabilities (simple average here, can use other methods)\n",
    "    combined_probs = (image_probs + spectrogram_probs) / 2\n",
    "    \n",
    "    # Final prediction\n",
    "    _, final_pred = torch.max(combined_probs, 1)\n",
    "    \n",
    "    return final_pred\n",
    "# Evaluate the model on the test set\n",
    "#accuracy = evaluate(fusion_model, test_loader)\n",
    "#print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test sets\n",
    "#spectrogram_accuracy = evaluate(spectrogram_model, spectrogram_test_loader)\n",
    "#simclr_accuracy = evaluate(simclr_model, simclr_test_loader)\n",
    "# Function to evaluate accuracy on the test dataset\n",
    "def evaluate_model(image_model, spectrogram_model, test_loader):\n",
    "    image_model.eval()\n",
    "    spectrogram_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, spectrograms, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = late_fusion(images, spectrograms)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_model.to(device)\n",
    "spectrogram_model.to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(image_model, spectrogram_model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "365a3ce6-3294-4d6c-9439-d098fbf75894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Weighted Fusion): 0.9971\n"
     ]
    }
   ],
   "source": [
    "#weighted average\n",
    "image_model.eval()\n",
    "spectrogram_model.eval()\n",
    "# Function to get predictions from both models\n",
    "def get_predictions(image_tensor, spectrogram_tensor):\n",
    "    with torch.no_grad():\n",
    "        image_output = image_model(image_tensor)\n",
    "        spectrogram_output = spectrogram_model(spectrogram_tensor)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    image_probs = F.softmax(image_output, dim=1)\n",
    "    spectrogram_probs = F.softmax(spectrogram_output, dim=1)\n",
    "    \n",
    "    return image_probs, spectrogram_probs\n",
    "\n",
    "def late_fusion_weighted(image_tensor, spectrogram_tensor, image_weight=0.5, spectrogram_weight=0.5):\n",
    "    image_probs, spectrogram_probs = get_predictions(image_tensor, spectrogram_tensor)\n",
    "    \n",
    "    # Ensure weights sum to 1\n",
    "    total_weight = image_weight + spectrogram_weight\n",
    "    image_weight /= total_weight\n",
    "    spectrogram_weight /= total_weight\n",
    "    \n",
    "    # Weighted average of the probabilities\n",
    "    combined_probs = image_weight * image_probs + spectrogram_weight * spectrogram_probs\n",
    "    \n",
    "    # Final prediction\n",
    "    _, final_pred = torch.max(combined_probs, 1)\n",
    "    \n",
    "    return final_pred\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset with weighted fusion\n",
    "def evaluate_model_weighted(image_model, spectrogram_model, test_loader, image_weight=0.5, spectrogram_weight=0.5):\n",
    "    image_model.eval()\n",
    "    spectrogram_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, spectrograms, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = late_fusion_weighted(images, spectrograms, image_weight, spectrogram_weight)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_model.to(device)\n",
    "spectrogram_model.to(device)\n",
    "\n",
    "# Evaluate the model with weighted average fusion\n",
    "accuracy_weighted = evaluate_model_weighted(image_model, spectrogram_model, test_loader, image_weight=0.6, spectrogram_weight=0.4)\n",
    "print(f'Test Accuracy (Weighted Fusion): {accuracy_weighted:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25665483-32c0-4381-b21e-06c8e336a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/plaiground/anaconda3/envs/ssl/lib/python3.11/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (92618880 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Logistic Regression Fusion): 0.9974\n"
     ]
    }
   ],
   "source": [
    "#logreg fusion\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "image_model.eval()\n",
    "spectrogram_model.eval()\n",
    "# Function to get predictions from both models\n",
    "def get_predictions(image_tensor, spectrogram_tensor):\n",
    "    with torch.no_grad():\n",
    "        image_output = image_model(image_tensor)\n",
    "        spectrogram_output = spectrogram_model(spectrogram_tensor)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    image_probs = F.softmax(image_output, dim=1)\n",
    "    spectrogram_probs = F.softmax(spectrogram_output, dim=1)\n",
    "    \n",
    "    return image_probs, spectrogram_probs\n",
    "\n",
    "def extract_features(image_model, spectrogram_model, dataloader):\n",
    "    image_model.eval()\n",
    "    spectrogram_model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, spectrograms, label in dataloader:\n",
    "            images = images.to(device)\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            image_output = image_model(images)\n",
    "            spectrogram_output = spectrogram_model(spectrograms)\n",
    "\n",
    "            image_probs = F.softmax(image_output, dim=1)\n",
    "            spectrogram_probs = F.softmax(spectrogram_output, dim=1)\n",
    "\n",
    "            combined_features = torch.cat((image_probs, spectrogram_probs), dim=1)\n",
    "            features.append(combined_features.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "# Extract features from the training set\n",
    "train_features, train_labels = extract_features(image_model, spectrogram_model, test_loader)\n",
    "\n",
    "# Train a logistic regression model on the extracted features\n",
    "log_reg = LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(train_features, train_labels)\n",
    "\n",
    "# Function to evaluate the logistic regression model\n",
    "def evaluate_log_reg(log_reg, image_model, spectrogram_model, test_loader):\n",
    "    features, labels = extract_features(image_model, spectrogram_model, test_loader)\n",
    "    preds = log_reg.predict(features)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return accuracy\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_model.to(device)\n",
    "spectrogram_model.to(device)\n",
    "\n",
    "\n",
    "# Evaluate the logistic regression model\n",
    "accuracy_log_reg = evaluate_log_reg(log_reg, image_model, spectrogram_model, test_loader)\n",
    "print(f'Test Accuracy (Logistic Regression Fusion): {accuracy_log_reg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " MangoDefend - Export Image Model to ONNX\n",
      "======================================================================\n",
      "\n",
      " Loading image model...\n",
      "    Model loaded: C:\\Users\\saefu\\Documents\\Mango-app-almost\\frontend\\models\\imgcnnmaldeb.pth\n",
      "\n",
      " Exporting to ONNX...\n",
      "   Input: [batch, 3, 224, 224]\n",
      "   Output: [batch, 2] (class probabilities)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saefu\\AppData\\Local\\Temp\\ipykernel_39788\\2572175975.py:56: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model berhasil diekspor!\n",
      "   Output: desktop_app/models\\Modelv3.onnx\n",
      "   Size: 42.63 MB\n",
      "\n",
      " Verifying ONNX model...\n",
      "    Model ONNX valid!\n",
      "\n",
      " Model Information:\n",
      "   Producer: pytorch\n",
      "   IR Version: 8\n",
      "   Opset: 18\n",
      "\n",
      "======================================================================\n",
      " Export selesai! Model siap digunakan di desktop_app\n",
      "======================================================================\n",
      "\n",
      " Cara menggunakan di desktop app:\n",
      "   import onnxruntime as ort\n",
      "   session = ort.InferenceSession('desktop_app/models/mango_image_model.onnx')\n",
      "   outputs = session.run(None, {'input': image_array})\n",
      "   probabilities = outputs[0]  # [benign_prob, malware_prob]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Export Image Model to ONNX untuk Desktop App\n",
    "# Model: Image CNN (imgcnnmaldeb) - Single Model\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load trained model\n",
    "image_model_path = \"C:\\\\Users\\\\saefu\\\\Documents\\\\Mango-app-almost\\\\frontend\\\\models\\\\imgcnnmaldeb.pth\"\n",
    "\n",
    "# Create model instance\n",
    "model = ImageClassifier(num_classes=2)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(image_model_path, map_location='cpu'), strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {image_model_path}\")\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Path output\n",
    "output_dir = \"desktop_app/models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"Modelv3.onnx\")\n",
    "\n",
    "print(f\"\\n Exporting to ONNX...\")\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    output_path,\n",
    "    export_params=True,\n",
    "    opset_version=18,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    dynamo=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\nModel berhasil diekspor!\")\n",
    "print(f\"   Output: {output_path}\")\n",
    "\n",
    "# Get file size\n",
    "file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"   Size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dd37560-f733-4476-a52e-d95e8c8f0671",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageClassifierWrapper' object has no attribute 'backbone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Train the fusion model\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m \u001b[43mtrain_fusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectrogram_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Evaluation function\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_fusion_model\u001b[39m(fusion_model, image_model, spectrogram_model, test_loader):\n",
      "Cell \u001b[0;32mIn[28], line 76\u001b[0m, in \u001b[0;36mtrain_fusion_model\u001b[0;34m(fusion_model, image_model, spectrogram_model, train_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     73\u001b[0m images, spectrograms \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), spectrograms\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m image_features \u001b[38;5;241m=\u001b[39m \u001b[43mimage_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m(images)\n\u001b[1;32m     77\u001b[0m spectrogram_features \u001b[38;5;241m=\u001b[39m spectrogram_model\u001b[38;5;241m.\u001b[39mbackbone(spectrograms)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Flatten features\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssl/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageClassifierWrapper' object has no attribute 'backbone'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class DeepFusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DeepFusionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#def get_label(path):\n",
    "\"\"\"\n",
    "#  Extracts label from the folder name of an image path.\n",
    "#\n",
    "#  Args:\n",
    "#      path (str): Path to the image file.\n",
    "\n",
    "#  Returns:\n",
    "#      str: Label extracted from the folder name.\n",
    "\"\"\"\n",
    "  # Split the path based on the directory separator\n",
    "#  folder_name = path.split(\"/\")[-1]  # Assuming \"/\" as separator\n",
    "#  return folder_name\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#image_model_path = '/path/to/image_model.pth'\n",
    "#spectrogram_model_path = '/path/to/spectrogram_model.pth'\n",
    "image_model_path = \"/home/plaiground/Documents/multimodal/imgcnndebi872a.pth\"\n",
    "spectrogram_model_path = \"/home/plaiground/Documents/multimodal/spectroCNNdebi872.pth\"\n",
    "\n",
    "image_model = ImageClassifierWrapper(image_model_path)\n",
    "#image_model_state = torch.load(image_model_path)\n",
    "image_model.to(device)\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "filtered_image_model_state = {k: v for k, v in image_model_state.items() if k in image_model.state_dict()}\n",
    "image_model.load_state_dict(filtered_image_model_state, strict=False)\n",
    "image_model.to(device)\n",
    "\n",
    "spectrogram_model = SpectrogramClassifierWrapper(spectrogram_model_path)\n",
    "spectrogram_model.to(device)\n",
    "\n",
    "# Fusion model\n",
    "input_dim = 512 * 4 * 4 + 512 * 4 * 4\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "\n",
    "fusion_model = DeepFusionModel(input_dim, hidden_dim, output_dim)\n",
    "fusion_model.to(device)\n",
    "\n",
    "# Training function\n",
    "def train_fusion_model(fusion_model, image_model, spectrogram_model, train_loader, num_epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(fusion_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        fusion_model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, spectrograms in train_loader:\n",
    "            images, spectrograms = images.to(device), spectrograms.to(device)\n",
    "\n",
    "            # Extract features\n",
    "            image_features = image_model.backbone(images)\n",
    "            spectrogram_features = spectrogram_model.backbone(spectrograms)\n",
    "\n",
    "            # Flatten features\n",
    "            image_features = torch.flatten(image_features, start_dim=1)\n",
    "            spectrogram_features = torch.flatten(spectrogram_features, start_dim=1)\n",
    "\n",
    "            # Concatenate features\n",
    "            combined_features = torch.cat((image_features, spectrogram_features), dim=1)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = fusion_model(combined_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Train the fusion model\n",
    "train_fusion_model(fusion_model, image_model, spectrogram_model, train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_fusion_model(fusion_model, image_model, spectrogram_model, test_loader):\n",
    "    fusion_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, spectrograms, labels in test_loader:\n",
    "            images, spectrograms, labels = images.to(device), spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            # Extract features\n",
    "            image_features = image_model.backbone(images)\n",
    "            spectrogram_features = spectrogram_model.backbone(spectrograms)\n",
    "\n",
    "            # Flatten features\n",
    "            image_features = torch.flatten(image_features, start_dim=1)\n",
    "            spectrogram_features = torch.flatten(spectrogram_features, start_dim=1)\n",
    "\n",
    "            # Concatenate features\n",
    "            combined_features = torch.cat((image_features, spectrogram_features), dim=1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = fusion_model(combined_features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the fusion model\n",
    "accuracy_fusion = evaluate_fusion_model(fusion_model, image_model, spectrogram_model, test_loader)\n",
    "print(f'Test Accuracy (Deep Fusion): {accuracy_fusion:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba78cc-ae04-4381-873f-af6d5f4a72ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
